'use server';
/**
 * @fileOverview A flow that allows users to query data using natural language and receive answers generated by an LLM.
 *
 * - queryDataWithLLM - A function that handles the data querying process.
 * - QueryDataWithLLMInput - The input type for the queryDataWithLLM function.
 * - QueryDataWithLLMOutput - The return type for the queryDataWithLLM function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const QueryDataWithLLMInputSchema = z.object({
  data: z.string().describe('The data to query.'),
  query: z.string().describe('The query to ask about the data.'),
});
export type QueryDataWithLLMInput = z.infer<typeof QueryDataWithLLMInputSchema>;

const QueryDataWithLLMOutputSchema = z.object({
  answer: z.string().describe('The answer to the query.'),
});
export type QueryDataWithLLMOutput = z.infer<typeof QueryDataWithLLMOutputSchema>;

export async function queryDataWithLLM(input: QueryDataWithLLMInput): Promise<QueryDataWithLLMOutput> {
  return queryDataWithLLMFlow(input);
}

const prompt = ai.definePrompt({
  name: 'queryDataWithLLMPrompt',
  input: {schema: QueryDataWithLLMInputSchema},
  output: {schema: QueryDataWithLLMOutputSchema},
  prompt: `You are an expert at answering questions about data.

  Here is the data:
  {{data}}

  Here is the question:
  {{query}}

  Answer the question using the data provided.
  `,
});

const queryDataWithLLMFlow = ai.defineFlow(
  {
    name: 'queryDataWithLLMFlow',
    inputSchema: QueryDataWithLLMInputSchema,
    outputSchema: QueryDataWithLLMOutputSchema,
  },
  async input => {
    const {output} = await prompt(input);
    return output!;
  }
);
